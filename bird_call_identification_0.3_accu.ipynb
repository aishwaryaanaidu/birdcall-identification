{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bird-call-identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNym1df5IdylL+AvAAcRicN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwaryaanaidu/birdcall-identification/blob/main/bird_call_identification_0.3_accu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc0hL_ZTuAU1",
        "outputId": "67762c5d-3dce-48f3-f231-e94275a0134b"
      },
      "source": [
        "pip install pydub flask_ngrok flask_cors"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: flask_cors in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UudrJ_orumCo",
        "outputId": "996deef8-41cc-4848-d9bd-8b09c3adb4b9"
      },
      "source": [
        "import librosa, librosa.display\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import torch\n",
        "# matplotlib inline\n",
        "from pydub import AudioSegment\n",
        "# import FigureCanvasAgg as FigureCanvas\n",
        "from os import path\n",
        "import subprocess\n",
        "import csv\n",
        "from csv import writer\n",
        "\n",
        "#Keras imports\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import model_from_json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing\n",
        "from matplotlib.image import imread\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "imheight = 350\n",
        "imwidth = 350\n",
        "\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRaXKSkixrIK"
      },
      "source": [
        "def img_to_numpy_array(path):\n",
        "    return imread(path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77dNS7KHzr0z"
      },
      "source": [
        "def create_spectrogram():\n",
        "    # imheight = 50\n",
        "    # imwidth = 34\n",
        "    train_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/train_spectr\"\n",
        "    test_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\"\n",
        "    ####\n",
        "    os.mkdir(train_dir)\n",
        "    os.mkdir(test_dir)\n",
        "    ####\n",
        "    for bird in os.listdir(directory)[:5]:\n",
        "        dir_len = len(os.listdir(directory + \"/\" + bird)[:5])\n",
        "        train_count = round(dir_len * 0.7)\n",
        "        count = 1\n",
        "        for filename in os.listdir(directory + \"/\" + bird)[:5]:\n",
        "            if count <= train_count:\n",
        "                new_dir = train_dir\n",
        "            else:\n",
        "                new_dir = test_dir\n",
        "            src = directory + \"/\" + bird + \"/\" + filename\n",
        "            save_path = new_dir + \"/\" + filename.split(\".\")[0] + \".png\"\n",
        "            # print(src)\n",
        "            # print(save_path)\n",
        "\n",
        "            dst = \"test.wav\"\n",
        "            # params\n",
        "            sampling = 21952\n",
        "            hop_length = 245\n",
        "            n_mels = 224\n",
        "            n_fft = 892\n",
        "            win_length = n_fft\n",
        "            plt.rcParams[\"figure.figsize\"] = [7.50, 5.00]\n",
        "            plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "            # convert mp3 to wav\n",
        "            sound = AudioSegment.from_mp3(src)\n",
        "            sound.export(dst, format=\"wav\")\n",
        "            signal, Fs = librosa.load(dst, sr=21952)\n",
        "\n",
        "            # Load signal and plot\n",
        "            signal,Fs = librosa.load(dst,sr=sampling,mono=True,res_type=\"kaiser_fast\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Create spectrogram and plot\n",
        "            spectr = librosa.feature.melspectrogram(signal, sr=sampling, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length,\n",
        "                                                    win_length=win_length, fmin=300)\n",
        "            log_spectr = librosa.amplitude_to_db(spectr)\n",
        "\n",
        "            librosa.display.specshow(log_spectr, sr=sampling, hop_length=hop_length)\n",
        "            ####\n",
        "            plt.savefig(save_path)\n",
        "            \n",
        "            gray = Image.open(save_path).convert('L')\n",
        "            gray.save(save_path)\n",
        "            ####\n",
        "            \n",
        "\n",
        "            count += 1\n",
        "    # return train_list, test_list"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jykGR_xgvNGO"
      },
      "source": [
        "def create_upload_spectrogram():\n",
        "  upload_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/uploads\"\n",
        "    ####\n",
        "  os.mkdir(upload_dir)\n",
        "  src = \"drive/MyDrive/Colab Notebooks/uploads/upload.mp3\"\n",
        "  save_path = upload_dir + \"/upload.png\"\n",
        "  # print(src)\n",
        "  # print(save_path)\n",
        "\n",
        "  dst = \"test.wav\"\n",
        "  # params\n",
        "  sampling = 21952\n",
        "  hop_length = 245\n",
        "  n_mels = 224\n",
        "  n_fft = 892\n",
        "  win_length = n_fft\n",
        "  plt.rcParams[\"figure.figsize\"] = [7.50, 5.00]\n",
        "  plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "  # convert mp3 to wav\n",
        "  sound = AudioSegment.from_mp3(src)\n",
        "  sound.export(dst, format=\"wav\")\n",
        "  signal, Fs = librosa.load(dst, sr=21952)\n",
        "\n",
        "  # Load signal and plot\n",
        "  signal,Fs = librosa.load(dst,sr=sampling,mono=True,res_type=\"kaiser_fast\")\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Create spectrogram and plot\n",
        "  spectr = librosa.feature.melspectrogram(signal, sr=sampling, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length,\n",
        "                                          win_length=win_length, fmin=300)\n",
        "  log_spectr = librosa.amplitude_to_db(spectr)\n",
        "\n",
        "  librosa.display.specshow(log_spectr, sr=sampling, hop_length=hop_length)\n",
        "  ####\n",
        "  plt.savefig(save_path)\n",
        "\n",
        "  gray = Image.open(save_path).convert('L')\n",
        "  gray.save(save_path)\n",
        "  ####"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMba5JtfxvgJ"
      },
      "source": [
        "def create_train_test(trl, tel):\n",
        "    train = pd.read_csv(\"drive/MyDrive/Colab Notebooks/train_data.csv\")\n",
        "    test = pd.read_csv(\"drive/MyDrive/Colab Notebooks/test_data.csv\")\n",
        "    # y_test = np.zeros(len(tel[1:]), str)\n",
        "    # y_train = np.zeros(len(trl[1:]), str)\n",
        "    y_test = np.empty((len(tel[1:]), 1), dtype=np.dtype('U100'))\n",
        "    y_train = np.empty((len(trl[1:]), 1), dtype=np.dtype('U100'))\n",
        "    x_train = np.zeros((len(trl[1:]), imheight, imwidth))\n",
        "    x_test = np.zeros((len(tel[1:]), imheight, imwidth))\n",
        "\n",
        "    for i, f in enumerate(tel[1:]):\n",
        "        y_test[i]     = f[1]\n",
        "        x_test[i,:,:] = img_to_numpy_array(f[0])\n",
        "\n",
        "    for i, f in enumerate(trl[1:]):\n",
        "        y_train[i]     = f[1]\n",
        "        x_train[i,:,:] = img_to_numpy_array(f[0])\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpzNOPUExy6S"
      },
      "source": [
        "def create_model(trl, tel):\n",
        "    # train = pd.read_csv(\"train.csv\")\n",
        "    # test = pd.read_csv(\"test.csv\")\n",
        "    # x_train, y_train, x_test, y_test = train[\"path\"], train[\"label\"], test[\"path\"], test[\"label\"]\n",
        "    x_train, y_train, x_test, y_test = create_train_test(trl, tel)\n",
        "\n",
        "    print(\"Size of Training Data:\", np.shape(x_train))\n",
        "    print(\"Size of Training Labels:\", np.shape(y_train))\n",
        "    print(\"Size of Test Data:\", np.shape(x_test))\n",
        "    print(\"Size of Test Labels:\", np.shape(y_test))\n",
        "    \n",
        "    # le = preprocessing.LabelEncoder()\n",
        "    le.fit([\"amerob\", \"blujay\", \"houspa\", \"norcar\"])\n",
        "    y_train = le.transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "    \n",
        "\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    x_train = x_train.reshape(x_train.shape[0], imheight, imwidth, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], imheight, imwidth, 1)\n",
        "    \n",
        "    input_shape = (imheight, imwidth, 1)\n",
        "    batch_size = 2\n",
        "    epochs = 1\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.25))    \n",
        "    model.add(Dense(128, activation='relu'))\n",
        "#     model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "#     opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "\n",
        "    model.fit(x_train, y_train, batch_size=4, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OjvRen_x2Hv"
      },
      "source": [
        "directory = \"drive/MyDrive/Colab Notebooks/IndianaBirds\"\n",
        "# trl, tel = create_spectrogram()\n",
        "\n",
        "# create_spectrogram()\n",
        "train_df = pd.read_csv(\"drive/MyDrive/Colab Notebooks/train_data.csv\")\n",
        "trl = train_df.values.tolist()\n",
        "test_df = pd.read_csv(\"drive/MyDrive/Colab Notebooks/test_data.csv\")\n",
        "tel = test_df.values.tolist()\n",
        "# print(tel)\n",
        "# list_to_csv(trl, tel)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC2SkPJ_yNSu"
      },
      "source": [
        "#Save created model\n",
        "def save_model_to_disk(model):\n",
        "    # serialize model to JSON\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"model.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "\n",
        "#Load saved model\n",
        "def load_model_from_disk():\n",
        "    # load json and create model\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "    return loaded_model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NccLG77yQaF",
        "outputId": "b0352313-0ef2-4f62-eb3d-6238ade334f5"
      },
      "source": [
        "num_classes = 4\n",
        "if(os.path.isfile('model.json')):\n",
        "    m = load_model_from_disk()\n",
        "else:\n",
        "    m = create_model(trl, tel)\n",
        "    save_model_to_disk(m)\n",
        "# m = create_model(trl, tel)\n",
        "print(m.summary())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of Training Data: (609, 350, 350)\n",
            "Size of Training Labels: (609, 1)\n",
            "Size of Test Data: (78, 350, 350)\n",
            "Size of Test Labels: (78, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 348, 348, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 346, 346, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 173, 173, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1915456)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1915456)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               245178496 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,197,828\n",
            "Trainable params: 245,197,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "153/153 [==============================] - 507s 3s/step - loss: 1.9809 - accuracy: 0.2808 - val_loss: 1.4108 - val_accuracy: 0.2308\n",
            "Epoch 2/10\n",
            "153/153 [==============================] - 502s 3s/step - loss: 1.3775 - accuracy: 0.2841 - val_loss: 1.3903 - val_accuracy: 0.2308\n",
            "Epoch 3/10\n",
            "153/153 [==============================] - 506s 3s/step - loss: 1.3642 - accuracy: 0.3153 - val_loss: 1.4304 - val_accuracy: 0.2308\n",
            "Epoch 4/10\n",
            "153/153 [==============================] - 507s 3s/step - loss: 1.3881 - accuracy: 0.2939 - val_loss: 1.3899 - val_accuracy: 0.2308\n",
            "Epoch 5/10\n",
            "153/153 [==============================] - 505s 3s/step - loss: 1.3820 - accuracy: 0.3038 - val_loss: 1.3912 - val_accuracy: 0.2308\n",
            "Epoch 6/10\n",
            "153/153 [==============================] - 505s 3s/step - loss: 1.3804 - accuracy: 0.3038 - val_loss: 1.3929 - val_accuracy: 0.2308\n",
            "Epoch 7/10\n",
            "153/153 [==============================] - 506s 3s/step - loss: 1.3804 - accuracy: 0.3054 - val_loss: 1.3940 - val_accuracy: 0.2308\n",
            "Epoch 8/10\n",
            "153/153 [==============================] - 504s 3s/step - loss: 1.3808 - accuracy: 0.3038 - val_loss: 1.3950 - val_accuracy: 0.2308\n",
            "Epoch 9/10\n",
            "153/153 [==============================] - 519s 3s/step - loss: 1.3794 - accuracy: 0.3038 - val_loss: 1.3955 - val_accuracy: 0.2308\n",
            "Epoch 10/10\n",
            "153/153 [==============================] - 513s 3s/step - loss: 1.3809 - accuracy: 0.3038 - val_loss: 1.3968 - val_accuracy: 0.2308\n",
            "Saved model to disk\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 348, 348, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 346, 346, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 173, 173, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1915456)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1915456)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               245178496 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,197,828\n",
            "Trainable params: 245,197,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC8HGQBQhW4n",
        "outputId": "fb51d91e-6293-4591-da2a-242261c2c86a"
      },
      "source": [
        "pip install shutil"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement shutil (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for shutil\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLuvGiNZyYC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8141ed-1d0b-4291-b02d-6e33dcc5a343"
      },
      "source": [
        "from flask import Flask, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS, cross_origin\n",
        "from flask import jsonify\n",
        "import shutil\n",
        "import PIL\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "app = Flask(__name__)\n",
        "cors = CORS(app)\n",
        "app.config['CORS_HEADERS'] = 'Content-Type'\n",
        "app.config['UPLOAD_FOLDER'] = 'drive/MyDrive/Colab Notebooks/uploads'\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@cross_origin()\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_file():\n",
        "    uploaded_file = request.files['file']\n",
        "    print(uploaded_file.filename)\n",
        "    if os.path.exists(\"drive/MyDrive/Colab Notebooks/Spectrograms/uploads\") and os.path.isdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/uploads\"):\n",
        "      shutil.rmtree(\"drive/MyDrive/Colab Notebooks/Spectrograms/uploads\")\n",
        "    if uploaded_file.filename != '':\n",
        "        uploaded_file.save(os.path.join(app.config['UPLOAD_FOLDER'], \"upload.mp3\"))\n",
        "\n",
        "    create_upload_spectrogram()\n",
        "    f_img = \"drive/MyDrive/Colab Notebooks/Spectrograms/uploads/upload.png\"\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((350,350))\n",
        "    img.save(f_img)\n",
        "    # return { \"message\": \"success\" }\n",
        "    temp = np.zeros((1, 350, 350))\n",
        "    temp[0,:,:] = img_to_numpy_array(\"drive/MyDrive/Colab Notebooks/Spectrograms/uploads/upload.png\")\n",
        "    temp.reshape(temp.shape[0], 350, 350, 1)\n",
        "    output = np.array(m.predict(temp))\n",
        "    print(output)\n",
        "    # print(output[output.argmax()])\n",
        "    predictions_test = le.inverse_transform([output.argmax()])\n",
        "    print(predictions_test)\n",
        "    data = { \"predictions\": predictions_test[0]}\n",
        "    return data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://51de-34-74-153-55.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "XC16914.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [06/Dec/2021 02:24:49] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29821712 0.23161118 0.23285787 0.23731382]]\n",
            "['amerob']\n",
            "XC499798.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [06/Dec/2021 02:25:30] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2982226  0.23161139 0.23284817 0.23731788]]\n",
            "['amerob']\n",
            "XC70304.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [06/Dec/2021 02:25:50] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29822066 0.23161206 0.23285188 0.23731539]]\n",
            "['amerob']\n",
            "XC67160.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [06/Dec/2021 02:26:11] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29823735 0.23161265 0.23283362 0.23731634]]\n",
            "['amerob']\n",
            "XC31164.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [06/Dec/2021 02:26:33] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29823086 0.23160928 0.23283924 0.2373206 ]]\n",
            "['amerob']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z1tJbNzIRaG"
      },
      "source": [
        "# import PIL\n",
        "# import os\n",
        "# from PIL import Image\n",
        "\n",
        "\n",
        "# f = \"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\"\n",
        "\n",
        "# for file in os.listdir(f):\n",
        "#     f_img = f+\"/\"+file\n",
        "#     img = Image.open(f_img)\n",
        "#     img = img.resize((350,350))\n",
        "#     img.save(f_img)"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}