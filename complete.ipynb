{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+CMNd46Q59yl6+eLm/cwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwaryaanaidu/birdcall-identification/blob/main/complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_uZdAfWiqBE"
      },
      "source": [
        "import librosa, librosa.display\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import torch\n",
        "# matplotlib inline\n",
        "from pydub import AudioSegment\n",
        "# import FigureCanvasAgg as FigureCanvas\n",
        "from os import path\n",
        "import subprocess\n",
        "import csv\n",
        "from csv import writer\n",
        "\n",
        "#Keras imports\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import model_from_json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing\n",
        "from matplotlib.image import imread\n",
        "\n",
        "imheight = 360\n",
        "imwidth = 540\n",
        "\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnk3mdoOYHaQ",
        "outputId": "28034b0d-038d-4750-ac6c-8b28768772dd"
      },
      "source": [
        "pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvB4h0oVi75W"
      },
      "source": [
        "def create_spectrogram():\n",
        "    # imheight = 50\n",
        "    # imwidth = 34\n",
        "    train_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/train_spectr\"\n",
        "    test_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\"\n",
        "    ####\n",
        "    os.mkdir(train_dir)\n",
        "    os.mkdir(test_dir)\n",
        "    ####\n",
        "    train_list = [[\"path\", \"label\"]]\n",
        "    test_list = [[\"path\", \"label\"]]\n",
        "    for bird in os.listdir(directory):\n",
        "        dir_len = len(os.listdir(directory + \"/\" + bird))\n",
        "        train_count = round(dir_len * 0.7)\n",
        "        count = 1\n",
        "        for filename in os.listdir(directory + \"/\" + bird):\n",
        "            if count <= train_count:\n",
        "                new_dir = train_dir\n",
        "                train_list.append([new_dir + \"/\" + filename.split(\".\")[0] + \".png\", bird])\n",
        "            else:\n",
        "                new_dir = test_dir\n",
        "                test_list.append([new_dir + \"/\" + filename.split(\".\")[0] + \".png\", bird])\n",
        "            src = directory + \"/\" + bird + \"/\" + filename\n",
        "            save_path = new_dir + \"/\" + filename.split(\".\")[0] + \".png\"\n",
        "            # print(src)\n",
        "            # print(save_path)\n",
        "\n",
        "            dst = \"test.wav\"\n",
        "            # params\n",
        "            sampling = 21952\n",
        "            hop_length = 245\n",
        "            n_mels = 224\n",
        "            n_fft = 892\n",
        "            win_length = n_fft\n",
        "            plt.rcParams[\"figure.figsize\"] = [7.50, 5.00]\n",
        "            plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "            # convert mp3 to wav\n",
        "            sound = AudioSegment.from_mp3(src)\n",
        "            sound.export(dst, format=\"wav\")\n",
        "            signal, Fs = librosa.load(dst, sr=21952)\n",
        "\n",
        "            # Load signal and plot\n",
        "            signal,Fs = librosa.load(dst,sr=sampling,mono=True,res_type=\"kaiser_fast\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Create spectrogram and plot\n",
        "            spectr = librosa.feature.melspectrogram(signal, sr=sampling, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length,\n",
        "                                                    win_length=win_length, fmin=300)\n",
        "            log_spectr = librosa.amplitude_to_db(spectr)\n",
        "\n",
        "            librosa.display.specshow(log_spectr, sr=sampling, hop_length=hop_length)\n",
        "            ####\n",
        "            plt.savefig(save_path)\n",
        "            \n",
        "            gray = Image.open(save_path).convert('L')\n",
        "            gray.save(save_path)\n",
        "            ####\n",
        "            \n",
        "\n",
        "            count += 1\n",
        "    return train_list, test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giFwgjVQjhww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11c7b6a-5888-4cd1-a805-495c9e23c000"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJcLBIFlmrX_"
      },
      "source": [
        "def list_to_csv(train_lis, test_lis):\n",
        "    file1 = open('train.csv', 'w+', newline = '')\n",
        "    file2 = open('test.csv', 'w+', newline = '')\n",
        "    with file1:\n",
        "        write = csv.writer(file1)\n",
        "        write.writerows(train_lis)\n",
        "    with file2:\n",
        "        write = csv.writer(file2)\n",
        "        write.writerows(test_lis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osinTwi2qMvL"
      },
      "source": [
        "def img_to_numpy_array(path):\n",
        "    return imread(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqnJQZgbpn2B"
      },
      "source": [
        "def create_train_test(trl, tel):\n",
        "    train = pd.read_csv(\"train.csv\")\n",
        "    test = pd.read_csv(\"test.csv\")\n",
        "    # y_test = np.zeros(len(tel[1:]), str)\n",
        "    # y_train = np.zeros(len(trl[1:]), str)\n",
        "    y_test = np.empty((len(tel[1:]), 1), dtype=np.dtype('U100'))\n",
        "    y_train = np.empty((len(trl[1:]), 1), dtype=np.dtype('U100'))\n",
        "    x_train = np.zeros((len(trl[1:]), imheight, imwidth))\n",
        "    x_test = np.zeros((len(tel[1:]), imheight, imwidth))\n",
        "\n",
        "    for i, f in enumerate(tel[1:]):\n",
        "        y_test[i]     = f[1]\n",
        "        x_test[i,:,:] = img_to_numpy_array(f[0])\n",
        "\n",
        "    for i, f in enumerate(trl[1:]):\n",
        "        y_train[i]     = f[1]\n",
        "        x_train[i,:,:] = img_to_numpy_array(f[0])\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKEeX829mv_J"
      },
      "source": [
        "def create_model(trl, tel):\n",
        "    # train = pd.read_csv(\"train.csv\")\n",
        "    # test = pd.read_csv(\"test.csv\")\n",
        "    # x_train, y_train, x_test, y_test = train[\"path\"], train[\"label\"], test[\"path\"], test[\"label\"]\n",
        "    x_train, y_train, x_test, y_test = create_train_test(trl, tel)\n",
        "\n",
        "    print(\"Size of Training Data:\", np.shape(x_train))\n",
        "    print(\"Size of Training Labels:\", np.shape(y_train))\n",
        "    print(\"Size of Test Data:\", np.shape(x_test))\n",
        "    print(\"Size of Test Labels:\", np.shape(y_test))\n",
        "    \n",
        "    # le = preprocessing.LabelEncoder()\n",
        "    le.fit([\"amerob\", \"blujay\", \"moudov\", \"norcar\"])\n",
        "    y_train = le.transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "    \n",
        "\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    x_train = x_train.reshape(x_train.shape[0], imheight, imwidth, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], imheight, imwidth, 1)\n",
        "    \n",
        "    input_shape = (imheight, imwidth, 1)\n",
        "    batch_size = 2\n",
        "    epochs = 1\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.25))    \n",
        "    model.add(Dense(128, activation='relu'))\n",
        "#     model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "#     opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "\n",
        "    model.fit(x_train, y_train, batch_size=4, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ri2BQjEmztw"
      },
      "source": [
        "directory = \"drive/MyDrive/Colab Notebooks/IndianaBirds\"\n",
        "trl, tel = create_spectrogram()\n",
        "list_to_csv(trl, tel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQSuOlkRbsmO"
      },
      "source": [
        "#Save created model\n",
        "def save_model_to_disk(model):\n",
        "    # serialize model to JSON\n",
        "    print(\"Hrrr\")\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"model.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "\n",
        "#Load saved model\n",
        "def load_model_from_disk():\n",
        "    print(\"Lrrrrr\")\n",
        "    # load json and create model\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "    return loaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTAj-aXsnr3U"
      },
      "source": [
        "num_classes = 4\n",
        "if(os.path.isfile('model.json')):\n",
        "    m = load_model_from_disk()\n",
        "else:\n",
        "    m = create_model(trl, tel)\n",
        "    save_model_to_disk(m)\n",
        "# m = create_model(trl, tel)\n",
        "print(m.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGbSUwFSYZj"
      },
      "source": [
        "# temp = np.zeros((1, imheight, imwidth))\n",
        "# temp[0,:,:] = img_to_numpy_array(\"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr/XC114083.png\")\n",
        "# temp.reshape(temp.shape[0], imheight, imwidth, 1)\n",
        "# output = np.array(m.predict(temp))\n",
        "# print(output)\n",
        "# # print(output[output.argmax()])\n",
        "# predictions_test = le.inverse_transform([output.argmax()])\n",
        "# print(predictions_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}