{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bird_bird.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4GlYS99dC1RH+0W0O10XS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishwaryaanaidu/birdcall-identification/blob/main/test_train_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "194Ff-xUFS5y",
        "outputId": "e3152d5e-11a6-498c-edb8-8182da7b9e2b"
      },
      "source": [
        "pip install pydub"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLeaZ76RKoto",
        "outputId": "117414e5-84d7-4bbb-ac28-79b3477d86f4"
      },
      "source": [
        "pip install flask_ngrok"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTgDliqjzBrL",
        "outputId": "925e38be-ac42-4f88-b34b-1991b143a0c5"
      },
      "source": [
        "pip install flask_cors"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.1.4)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask_cors) (1.15.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask_cors) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.9->flask_cors) (2.0.1)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-3.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_uZdAfWiqBE"
      },
      "source": [
        "import librosa, librosa.display\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import torch\n",
        "# matplotlib inline\n",
        "from pydub import AudioSegment\n",
        "# import FigureCanvasAgg as FigureCanvas\n",
        "from os import path\n",
        "import subprocess\n",
        "import csv\n",
        "from csv import writer\n",
        "\n",
        "#Keras imports\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import model_from_json\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing\n",
        "from matplotlib.image import imread\n",
        "\n",
        "imheight = 360\n",
        "imwidth = 540\n",
        "\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8r5YGQob0sf"
      },
      "source": [
        "train_list = []\n",
        "directory = \"drive/MyDrive/Colab Notebooks/IndianaBirds\"\n",
        "for bird in os.listdir(directory):\n",
        "  for filename in os.listdir(directory + \"/\" + bird):\n",
        "    train_list.append([filename.split(\".\")[0] + \".png\", bird])\n",
        "file1 = open('dabba.csv', 'w+', newline = '')\n",
        "with file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(train_list)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8TFXnbmeP6w"
      },
      "source": [
        "filename = 'drive/MyDrive/Colab Notebooks/test_data1.csv'\n",
        "\n",
        "df = pd.read_csv(\"dabba.csv\")\n",
        "trl2 = df.values.tolist()\n",
        "\n",
        "testt = []\n",
        "with open(filename, 'r') as csvfile:\n",
        "    datareader = csv.reader(csvfile)\n",
        "    for row in datareader:\n",
        "        if row in trl2:\n",
        "          testt.append(row)\n",
        "file1 = open('dabba1.csv', 'w+', newline = '')\n",
        "with file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(testt)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvB4h0oVi75W"
      },
      "source": [
        "def create_spectrogram():\n",
        "    # imheight = 50\n",
        "    # imwidth = 34\n",
        "    train_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/train_spectrograms\"\n",
        "    test_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectrograms\"\n",
        "    ####\n",
        "    os.mkdir(train_dir)\n",
        "    os.mkdir(test_dir)\n",
        "    ####\n",
        "    train_list = [[\"path\", \"label\"]]\n",
        "    test_list = [[\"path\", \"label\"]]\n",
        "    for bird in os.listdir(directory)[:5]:\n",
        "        dir_len = len(os.listdir(directory + \"/\" + bird)[:5])\n",
        "        train_count = round(dir_len * 0.7)\n",
        "        count = 1\n",
        "        for filename in os.listdir(directory + \"/\" + bird)[:5]:\n",
        "            if count <= train_count:\n",
        "                new_dir = train_dir\n",
        "                train_list.append([new_dir + \"/\" + filename.split(\".\")[0] + \".png\", bird])\n",
        "            else:\n",
        "                new_dir = test_dir\n",
        "                test_list.append([new_dir + \"/\" + filename.split(\".\")[0] + \".png\", bird])\n",
        "            src = directory + \"/\" + bird + \"/\" + filename\n",
        "            save_path = new_dir + \"/\" + filename.split(\".\")[0] + \".png\"\n",
        "            # print(src)\n",
        "            # print(save_path)\n",
        "\n",
        "            dst = \"test.wav\"\n",
        "            # params\n",
        "            sampling = 21952\n",
        "            hop_length = 245\n",
        "            n_mels = 224\n",
        "            n_fft = 892\n",
        "            win_length = n_fft\n",
        "            plt.rcParams[\"figure.figsize\"] = [7.50, 5.00]\n",
        "            plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "            # convert mp3 to wav\n",
        "            sound = AudioSegment.from_mp3(src)\n",
        "            sound.export(dst, format=\"wav\")\n",
        "            signal, Fs = librosa.load(dst, sr=21952)\n",
        "\n",
        "            # Load signal and plot\n",
        "            signal,Fs = librosa.load(dst,sr=sampling,mono=True,res_type=\"kaiser_fast\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Create spectrogram and plot\n",
        "            spectr = librosa.feature.melspectrogram(signal, sr=sampling, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length,\n",
        "                                                    win_length=win_length, fmin=300)\n",
        "            log_spectr = librosa.amplitude_to_db(spectr)\n",
        "\n",
        "            librosa.display.specshow(log_spectr, sr=sampling, hop_length=hop_length)\n",
        "            ####\n",
        "            plt.savefig(save_path)\n",
        "            \n",
        "            gray = Image.open(save_path).convert('L')\n",
        "            gray.save(save_path)\n",
        "            ####\n",
        "            \n",
        "\n",
        "            count += 1\n",
        "    # return train_list, test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giFwgjVQjhww",
        "outputId": "fb48d42a-59b7-4e9e-ed65-e294f9c98eb1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJcLBIFlmrX_"
      },
      "source": [
        "def list_to_csv(train_lis, test_lis):\n",
        "    file1 = open('train.csv', 'w+', newline = '')\n",
        "    file2 = open('test.csv', 'w+', newline = '')\n",
        "    with file1:\n",
        "        write = csv.writer(file1)\n",
        "        write.writerows(train_lis)\n",
        "    with file2:\n",
        "        write = csv.writer(file2)\n",
        "        write.writerows(test_lis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osinTwi2qMvL"
      },
      "source": [
        "def img_to_numpy_array(path):\n",
        "    return imread(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqnJQZgbpn2B"
      },
      "source": [
        "def create_train_test(trl, tel):\n",
        "    train = pd.read_csv(\"train.csv\")\n",
        "    test = pd.read_csv(\"test.csv\")\n",
        "    # y_test = np.zeros(len(tel[1:]), str)\n",
        "    # y_train = np.zeros(len(trl[1:]), str)\n",
        "    y_test = np.empty((len(tel[1:]), 1), dtype=np.dtype('U100'))\n",
        "    y_train = np.empty((len(trl[1:]), 1), dtype=np.dtype('U100'))\n",
        "    x_train = np.zeros((len(trl[1:]), imheight, imwidth))\n",
        "    x_test = np.zeros((len(tel[1:]), imheight, imwidth))\n",
        "\n",
        "    for i, f in enumerate(tel[1:]):\n",
        "        y_test[i]     = f[1]\n",
        "        x_test[i,:,:] = img_to_numpy_array(f[0])\n",
        "\n",
        "    for i, f in enumerate(trl[1:]):\n",
        "        y_train[i]     = f[1]\n",
        "        x_train[i,:,:] = img_to_numpy_array(f[0])\n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKEeX829mv_J"
      },
      "source": [
        "def create_model(trl, tel):\n",
        "    # train = pd.read_csv(\"train.csv\")\n",
        "    # test = pd.read_csv(\"test.csv\")\n",
        "    # x_train, y_train, x_test, y_test = train[\"path\"], train[\"label\"], test[\"path\"], test[\"label\"]\n",
        "    x_train, y_train, x_test, y_test = create_train_test(trl, tel)\n",
        "\n",
        "    print(\"Size of Training Data:\", np.shape(x_train))\n",
        "    print(\"Size of Training Labels:\", np.shape(y_train))\n",
        "    print(\"Size of Test Data:\", np.shape(x_test))\n",
        "    print(\"Size of Test Labels:\", np.shape(y_test))\n",
        "    \n",
        "    # le = preprocessing.LabelEncoder()\n",
        "    le.fit([\"amerob\", \"blujay\", \"moudov\", \"norcar\"])\n",
        "    y_train = le.transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "    \n",
        "\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    x_train = x_train.reshape(x_train.shape[0], imheight, imwidth, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], imheight, imwidth, 1)\n",
        "    \n",
        "    input_shape = (imheight, imwidth, 1)\n",
        "    batch_size = 2\n",
        "    epochs = 1\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.25))    \n",
        "    model.add(Dense(128, activation='relu'))\n",
        "#     model.add(Flatten())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "#     opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "\n",
        "    model.fit(x_train, y_train, batch_size=4, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ri2BQjEmztw",
        "outputId": "3dba2e40-b3cd-400b-96af-e3d2c726af2b"
      },
      "source": [
        "directory = \"drive/MyDrive/Colab Notebooks/IndianaBirds\"\n",
        "# trl, tel = create_spectrogram()\n",
        "create_spectrogram()\n",
        "train_df = pd.read_csv(\"drive/MyDrive/Colab Notebooks/train_data.csv\")\n",
        "trl = train_df.values.tolist()\n",
        "test_df = pd.read_csv(\"drive/MyDrive/Colab Notebooks/test_data.csv\")\n",
        "tel = test_df.values.tolist()\n",
        "# print(tel)\n",
        "# list_to_csv(trl, tel)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['XC351871.png', 'amerob'], ['XC351879.png', 'amerob'], ['XC353375.png', 'amerob'], ['XC361931.png', 'amerob'], ['XC364119.png', 'amerob'], ['XC364638.png', 'amerob'], ['XC369855.png', 'amerob'], ['XC374685.png', 'amerob'], ['XC377115.png', 'amerob'], ['XC390282.png', 'amerob'], ['XC398608.png', 'amerob'], ['XC402800.png', 'amerob'], ['XC406162.png', 'amerob'], ['XC418153.png', 'amerob'], ['XC418265.png', 'amerob'], ['XC421278.png', 'amerob'], ['XC423450.png', 'amerob'], ['XC423451.png', 'amerob'], ['XC425811.png', 'amerob'], ['XC385658.png', 'blujay'], ['XC385659.png', 'blujay'], ['XC385660.png', 'blujay'], ['XC385661.png', 'blujay'], ['XC390596.png', 'blujay'], ['XC391728.png', 'blujay'], ['XC391964.png', 'blujay'], ['XC392232.png', 'blujay'], ['XC394311.png', 'blujay'], ['XC395464.png', 'blujay'], ['XC413285.png', 'blujay'], ['XC418322.png', 'blujay'], ['XC421950.png', 'blujay'], ['XC425570.png', 'blujay'], ['XC433419.png', 'blujay'], ['XC434250.png', 'blujay'], ['XC436044.png', 'blujay'], ['XC436435.png', 'blujay'], ['XC438594.png', 'blujay'], ['XC438595.png', 'blujay'], ['XC445790.png', 'norcar'], ['XC445798.png', 'norcar'], ['XC445799.png', 'norcar'], ['XC452140.png', 'norcar'], ['XC453939.png', 'norcar'], ['XC454294.png', 'norcar'], ['XC454295.png', 'norcar'], ['XC456864.png', 'norcar'], ['XC456916.png', 'norcar'], ['XC460879.png', 'norcar'], ['XC460880.png', 'norcar'], ['XC460882.png', 'norcar'], ['XC464020.png', 'norcar'], ['XC468936.png', 'norcar'], ['XC472251.png', 'norcar'], ['XC475008.png', 'norcar'], ['XC475010.png', 'norcar'], ['XC475144.png', 'norcar'], ['XC481413.png', 'norcar'], ['XC482489.png', 'norcar'], ['XC445790.png', 'houspa'], ['XC445798.png', 'houspa'], ['XC445799.png', 'houspa'], ['XC452140.png', 'houspa'], ['XC453939.png', 'houspa'], ['XC454294.png', 'houspa'], ['XC454295.png', 'houspa'], ['XC456864.png', 'houspa'], ['XC456916.png', 'houspa'], ['XC460879.png', 'houspa'], ['XC460880.png', 'houspa'], ['XC460882.png', 'houspa'], ['XC464020.png', 'houspa'], ['XC468936.png', 'houspa'], ['XC472251.png', 'houspa'], ['XC475008.png', 'houspa'], ['XC475010.png', 'houspa'], ['XC475144.png', 'houspa'], ['XC481413.png', 'houspa'], ['XC482489.png', 'houspa'], ['XC492590.png', 'houspa'], ['XC494688.png', 'houspa'], ['XC497032.png', 'houspa'], ['XC497792.png', 'houspa'], ['XC499798.png', 'houspa'], ['XC62768.png', 'houspa'], ['XC62769.png', 'houspa'], ['XC67162.png', 'houspa'], ['XC70304.png', 'houspa'], ['XC70942.png', 'houspa'], ['XC81291.png', 'houspa'], ['XC86756.png', 'houspa'], ['XC282991.png', 'houspa'], ['XC286524.png', 'houspa'], ['XC287874.png', 'houspa'], ['XC288484.png', 'houspa'], ['XC297291.png', 'houspa'], ['XC297495.png', 'houspa'], ['XC303678.png', 'houspa'], ['XC304524.png', 'houspa'], ['XC304525.png', 'houspa'], ['XC304861.png', 'houspa'], ['XC308809.png', 'houspa'], ['XC309817.png', 'houspa'], ['XC309819.png', 'houspa'], ['XC309821.png', 'houspa'], ['XC310251.png', 'houspa'], ['XC310332.png', 'houspa'], ['XC310953.png', 'houspa'], ['XC310955.png', 'houspa'], ['XC31164.png', 'houspa'], ['XC313476.png', 'houspa'], ['XC179164.png', 'houspa'], ['XC179165.png', 'houspa'], ['XC179338.png', 'houspa'], ['XC179339.png', 'houspa'], ['XC179340.png', 'houspa'], ['XC179341.png', 'houspa'], ['XC179342.png', 'houspa'], ['XC179343.png', 'houspa'], ['XC180085.png', 'houspa'], ['XC182594.png', 'houspa'], ['XC182595.png', 'houspa'], ['XC182702.png', 'houspa'], ['XC182704.png', 'houspa'], ['XC182716.png', 'houspa'], ['XC183686.png', 'houspa'], ['XC183866.png', 'houspa'], ['XC184442.png', 'houspa'], ['XC184801.png', 'houspa'], ['XC184832.png', 'houspa'], ['XC184833.png', 'houspa']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQSuOlkRbsmO"
      },
      "source": [
        "#Save created model\n",
        "def save_model_to_disk(model):\n",
        "    # serialize model to JSON\n",
        "    print(\"Hrrr\")\n",
        "    model_json = model.to_json()\n",
        "    with open(\"model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"model.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "\n",
        "#Load saved model\n",
        "def load_model_from_disk():\n",
        "    print(\"Lrrrrr\")\n",
        "    # load json and create model\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "    return loaded_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTAj-aXsnr3U",
        "outputId": "2f9f2d71-4e69-45a0-fbc2-d59a4d5b9ec3"
      },
      "source": [
        "num_classes = 4\n",
        "if(os.path.isfile('model.json')):\n",
        "    m = load_model_from_disk()\n",
        "else:\n",
        "    m = create_model(trl, tel)\n",
        "    save_model_to_disk(m)\n",
        "# m = create_model(trl, tel)\n",
        "print(m.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Training Data: (16, 360, 540)\n",
            "Size of Training Labels: (16, 1)\n",
            "Size of Test Data: (4, 360, 540)\n",
            "Size of Test Labels: (4, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 358, 538, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 356, 536, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 178, 268, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3053056)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3053056)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               390791296 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,810,628\n",
            "Trainable params: 390,810,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 22s 5s/step - loss: 42.8441 - accuracy: 0.2500 - val_loss: 8.5612 - val_accuracy: 0.2500\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 20.4980 - accuracy: 0.1875 - val_loss: 3.2653 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 18s 5s/step - loss: 5.1569 - accuracy: 0.3750 - val_loss: 1.3776 - val_accuracy: 0.2500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 18s 4s/step - loss: 1.2348 - accuracy: 0.5000 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 1.3366 - accuracy: 0.5000 - val_loss: 1.3941 - val_accuracy: 0.2500\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 1.2277 - accuracy: 0.6250 - val_loss: 1.3967 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 0.9421 - accuracy: 0.6250 - val_loss: 1.4732 - val_accuracy: 0.2500\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 0.8342 - accuracy: 0.5625 - val_loss: 1.5150 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 0.5937 - accuracy: 0.9375 - val_loss: 1.6152 - val_accuracy: 0.2500\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 19s 5s/step - loss: 0.6115 - accuracy: 0.8750 - val_loss: 1.6190 - val_accuracy: 0.0000e+00\n",
            "Hrrr\n",
            "Saved model to disk\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 358, 538, 32)      320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 356, 536, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 178, 268, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3053056)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3053056)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               390791296 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,810,628\n",
            "Trainable params: 390,810,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGbSUwFSYZj"
      },
      "source": [
        "# from flask import Flask, jsonify, request\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# app = Flask(__name__)\n",
        "# run_with_ngrok(app)\n",
        "\n",
        "# @app.route('/')\n",
        "# def hello():\n",
        "#     temp = np.zeros((1, imheight, imwidth))\n",
        "#     temp[0,:,:] = img_to_numpy_array(\"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr/XC133570.png\")\n",
        "#     temp.reshape(temp.shape[0], imheight, imwidth, 1)\n",
        "#     output = np.array(m.predict(temp))\n",
        "#     print(output)\n",
        "#     # print(output[output.argmax()])\n",
        "#     predictions_test = le.inverse_transform([output.argmax()])\n",
        "#     print(predictions_test)\n",
        "#     return predictions_test[0]\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#   app.run()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j80uqMrnbDx"
      },
      "source": [
        "def create_upload_spectrogram():\n",
        "  upload_dir = \"drive/MyDrive/Colab Notebooks/Spectrograms/uploads\"\n",
        "    ####\n",
        "  os.mkdir(upload_dir)\n",
        "  src = \"drive/MyDrive/Colab Notebooks/uploads/upload.mp3\"\n",
        "  save_path = upload_dir + \"/upload.png\"\n",
        "  # print(src)\n",
        "  # print(save_path)\n",
        "\n",
        "  dst = \"test.wav\"\n",
        "  # params\n",
        "  sampling = 21952\n",
        "  hop_length = 245\n",
        "  n_mels = 224\n",
        "  n_fft = 892\n",
        "  win_length = n_fft\n",
        "  plt.rcParams[\"figure.figsize\"] = [7.50, 5.00]\n",
        "  plt.rcParams[\"figure.autolayout\"] = True\n",
        "\n",
        "  # convert mp3 to wav\n",
        "  sound = AudioSegment.from_mp3(src)\n",
        "  sound.export(dst, format=\"wav\")\n",
        "  signal, Fs = librosa.load(dst, sr=21952)\n",
        "\n",
        "  # Load signal and plot\n",
        "  signal,Fs = librosa.load(dst,sr=sampling,mono=True,res_type=\"kaiser_fast\")\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Create spectrogram and plot\n",
        "  spectr = librosa.feature.melspectrogram(signal, sr=sampling, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length,\n",
        "                                          win_length=win_length, fmin=300)\n",
        "  log_spectr = librosa.amplitude_to_db(spectr)\n",
        "\n",
        "  librosa.display.specshow(log_spectr, sr=sampling, hop_length=hop_length)\n",
        "  ####\n",
        "  plt.savefig(save_path)\n",
        "\n",
        "  gray = Image.open(save_path).convert('L')\n",
        "  gray.save(save_path)\n",
        "  ####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K8tABUBbh0g",
        "outputId": "0fd31e5b-25e7-4446-ce6d-b77369b63016"
      },
      "source": [
        "from flask import Flask, jsonify, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS, cross_origin\n",
        "from flask import jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "cors = CORS(app)\n",
        "app.config['CORS_HEADERS'] = 'Content-Type'\n",
        "app.config['UPLOAD_FOLDER'] = 'drive/MyDrive/Colab Notebooks/uploads'\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@cross_origin()\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_file():\n",
        "    uploaded_file = request.files['file']\n",
        "    # print(uploaded_file.filename)\n",
        "    # if uploaded_file.filename != '':\n",
        "    #     uploaded_file.save(os.path.join(app.config['UPLOAD_FOLDER'], \"upload.mp3\"))\n",
        "\n",
        "    # create_upload_spectrogram()\n",
        "    # # return { \"message\": \"success\" }\n",
        "    # temp = np.zeros((1, imheight, imwidth))\n",
        "    # temp[0,:,:] = img_to_numpy_array(\"drive/MyDrive/Colab Notebooks/Spectrograms/uploads/upload.png\")\n",
        "    # temp.reshape(temp.shape[0], imheight, imwidth, 1)\n",
        "    # output = np.array(m.predict(temp))\n",
        "    # print(output)\n",
        "    # # print(output[output.argmax()])\n",
        "    # predictions_test = le.inverse_transform([output.argmax()])\n",
        "    # print(predictions_test)\n",
        "    data = { \"predictions\": \"amerob\"}\n",
        "    return data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://e6a4-35-221-218-113.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [04/Dec/2021 19:07:39] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Dec/2021 19:08:43] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Dec/2021 19:09:30] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Dec/2021 19:12:49] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Dec/2021 19:13:20] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [04/Dec/2021 19:19:11] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N4vkaj5NE3l"
      },
      "source": [
        "train_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/train_spectr\")[:187]:\n",
        "  train_list.append([filename.split(\".\")[0] + \".png\", \"amerob\"])\n",
        "file1 = open('train_data.csv', 'w+', newline = '')    \n",
        "with file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(train_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OklDiHaZOj43"
      },
      "source": [
        "train_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/train_spectr\")[187:]:\n",
        "  train_list.append([filename.split(\".\")[0] + \".png\", \"blujay\"])\n",
        "with open(\"train_data.csv\", \"a\") as file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(train_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uElHn9QQnGC"
      },
      "source": [
        "train_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/dump train\"):\n",
        "  train_list.append([filename.split(\".\")[0] + \".png\", \"norcar\"])\n",
        "with open(\"train_data.csv\", \"a\") as file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(train_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnnruL1vimHH"
      },
      "source": [
        "train_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/dump train\"):\n",
        "  train_list.append([filename.split(\".\")[0] + \".png\", \"houspa\"])\n",
        "with open(\"drive/MyDrive/Colab Notebooks/train_data.csv\", \"a\") as file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(train_list)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG4tqYZJFZXB"
      },
      "source": [
        "test_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\")[:20]:\n",
        "  test_list.append([filename.split(\".\")[0] + \".png\", \"amerob\"])\n",
        "file1 = open('drive/MyDrive/Colab Notebooks/test_data1.csv', 'w+', newline = '')    \n",
        "with file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(test_list)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6-tGfBoGSHu"
      },
      "source": [
        "test_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\")[20:40]:\n",
        "  test_list.append([filename.split(\".\")[0] + \".png\", \"blujay\"])\n",
        "with open(\"drive/MyDrive/Colab Notebooks/test_data1.csv\", \"a\") as file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(test_list)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU3VnxsRGtZ7"
      },
      "source": [
        "test_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\")[40:92]:\n",
        "  test_list.append([filename.split(\".\")[0] + \".png\", \"norcar\"])\n",
        "with open(\"drive/MyDrive/Colab Notebooks/test_data1.csv\", \"a\") as file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(test_list)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijtm4XWBG13o"
      },
      "source": [
        "test_list = []\n",
        "for filename in os.listdir(\"drive/MyDrive/Colab Notebooks/Spectrograms/test_spectr\")[92:]:\n",
        "  test_list.append([filename.split(\".\")[0] + \".png\", \"houspa\"])\n",
        "with open(\"drive/MyDrive/Colab Notebooks/test_data1.csv\", \"a\") as file1:\n",
        "    write = csv.writer(file1)\n",
        "    write.writerows(test_list)"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}